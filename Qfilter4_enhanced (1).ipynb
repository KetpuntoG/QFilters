{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Team Name: CCH\n",
    "\n",
    "### Project Description:\n",
    "The emerging field of hybrid quantum-classical algorithms joins CPUs and QPUs to speed up specific calculations within a classical algorithm. This allows for shorter quantum executions that are less susceptible to the cumulative effects of noise and that run well on today’s devices. This is why we intend to explore the performance of a hybrid convolutional neural network model that incorporates a trainable quantum layer, effectively replacing a convolutional filter, in both quantum simulators and QPU.\n",
    "\n",
    "Our team proposes to design a trainable quantum convolutional filter in a  quantum-classical  hybrid neural network, appealing for the NISQ era, inspired by these papers: Hybrid quantum-classical Convolutional Neural Networks [1] and Quanvolutional Neural Networks [2] , but generalizing these previous works to use cloud based QPU. \n",
    "<img src=\"QF4_1.jpeg\" width=50%, height=50% >\n",
    "\n",
    "Here is a list of the expected outcomes of this project:\n",
    "\n",
    "-  Complete benchmarking of a quantum convolutional filter (Encoding of data + variational ansatz) embedded in a classical neural network, in the context of an image classification task with the MNIST dataset. \n",
    "- Example of complete workflow for training a quantum-classical CNN interfacing Pennylane  with Pytorch for automatic differentiation of the quantum and classical layers, and amazon braket for running the workflow on a QPU.\n",
    "- With the current noise level in cloud-based QPU, what size/depth of the parametrized quantum circuits makes the model unable to learn, with.. (mejorar frase) . Can we achieve a significant advantage (in terms of evaluation metrics for a fixed number of quantum vs classical parameters/weights) with today’s QPU?\n",
    "-  Visual exploration of convolved features ( output of filters) with both quantum and classical convolutional filters.\n",
    "\n",
    "<img src=\"AmazonLambda.jpeg\" width=50%, height=50% >\n",
    "\n",
    "<img src=\"Amazon-Braket.jpeg\" width=50%, height=50% >\n",
    "\n",
    "To achieve our goal, we defined a scenario in which we implement a classic convolutional network with the Tensorflow framework. To embed our quantum variational filter, we had had to undo part of that implementation. This small modification caused a little efficiency lost in this phase. Still, the idea is to use the 4000 $ credit to use an AWS Lambda function controller in Python [3] and to parallelize it to achieve the same efficiency that we would get with the TensorFlow library. And also, for computing gradients in parallel with the Pennylane-Braket plugin. \n",
    "Another aspect to consider is that to develop an interpretation and visual benchmark system of the classical and quantum convolutional filters, it is necessary to implement the improvement mentioned above.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General setup Libreries\n",
    "This Python code requires PennyLane with the TensorFlow interface and the plotting library matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The Libraies and dependecies that we need\n",
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "from pennylane.templates import RandomLayers\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting of the main hyper-parameters of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 1   # Number of optimization epochs\n",
    "n_layers = 1    # Number of random layers\n",
    "n_train = 5     # Size of the train dataset\n",
    "n_test = 1      # Size of the test dataset\n",
    "wires = 4\n",
    "\n",
    "np.random.seed(0)           # Seed for NumPy random number generator\n",
    "tf.random.set_seed(0)       # Seed for TensorFlow random number generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading of the MNIST dataset\n",
    "We import the MNIST dataset from Keras. In this release we use only a small number of training and test images. \n",
    "But, at the end of the QHack we will use the full dataset to achieve better results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_dataset = keras.datasets.mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist_dataset.load_data()\n",
    "\n",
    "# Reduce dataset size\n",
    "train_images = train_images[:n_train]\n",
    "train_labels = tf.convert_to_tensor(train_labels[:n_train])\n",
    "test_images = test_images[:n_test]\n",
    "test_labels = tf.convert_to_tensor(test_labels[:n_test])\n",
    "\n",
    "# Normalize pixel values within 0 and 1\n",
    "train_images = train_images / 255\n",
    "test_images = test_images / 255\n",
    "\n",
    "# Add extra dimension for convolution channels\n",
    "train_images = tf.convert_to_tensor(train_images[..., tf.newaxis])\n",
    "test_images = tf.convert_to_tensor(test_images[..., tf.newaxis])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantum Variational Circuit as a convolution quantum Filter\n",
    "\n",
    "Here we implement the quantum part with the given ansatz.  trainable quantum convolutional filter in a  quantum-classical  hybrid neural network, appealing for the NISQ era, inspired by these papers: Hybrid quantum-classical Convolutional Neural Networks [1] and Quanvolutional Neural Networks [2], but generalizing these previous works to use cloud based QPU.\n",
    "\n",
    "NOTE: \n",
    "IN THIS RELEASE, WE ARE ONLY PARALELIZING WITH AMAZON BRAKET. AFTER WE WILL NEED TO IMPLEMENT (WITH THE CREDIT) THE AWS LAMBDA FUNCTION \n",
    "\n",
    "We rewrote some of the code in TensorFlow to better match our quantum filter with Pennylane and prepared it for Amazon-Braket.\n",
    "\n",
    "We initialize a PennyLane ``default.qubit`` device, simulating a system of $4$ qubits.\n",
    "The associated ``qnode`` represents the quantum circuit consisting of:\n",
    "\n",
    "1. an embedding layer of local $R_y$ rotations (with angles scaled by a factor of $\\pi$);\n",
    "\n",
    "2. a circuit of ``n_layers``;\n",
    "\n",
    "3. a final measurement in the computational basis $Z$, estimating $4$ expectation values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1\n",
      "tf.Tensor(1.1720953303540578, shape=(), dtype=float64)\n",
      "tf.Tensor(1.0123008651066379, shape=(), dtype=float64)\n",
      "tf.Tensor(1.122545252797636, shape=(), dtype=float64)\n",
      "tf.Tensor(0.9919308095145103, shape=(), dtype=float64)\n",
      "tf.Tensor(0.951554340856178, shape=(), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "    \n",
    "    def quanv(image, params, filters = 1):\n",
    "        \n",
    "        out = tf.zeros((14, 14, filters))\n",
    "        # Loop over the coordinates of the top-left pixel of 2X2 squares\n",
    "        I = []\n",
    "        for i in range(filters):\n",
    "            J = []\n",
    "            for j in range(0, 28, 2):\n",
    "                K = []\n",
    "                for k in range(0, 28, 2):\n",
    "                    # Process a squared 2x2 region of the image with a quantum circuit\n",
    "                    \n",
    "                    q_results = scalar_prod(\n",
    "                        tf.convert_to_tensor([\n",
    "                            image[j, k, 0],\n",
    "                            image[j, k + 1, 0],\n",
    "                            image[j + 1, k, 0],\n",
    "                            image[j + 1, k + 1, 0]\n",
    "                        ]), params[i]\n",
    "                    )\n",
    "                    # Assign expectation values to different channels of the output pixel (j/2, k/2)\n",
    "                    K.append(q_results)\n",
    "                J.append(K)\n",
    "            I.append(J)\n",
    "        return tf.convert_to_tensor(I)\n",
    "    \n",
    "    def scalar_prod(phi, params):\n",
    "\n",
    "        prob = circuit(phi,params)[0]\n",
    "        return prob\n",
    "   \n",
    "    #Here dev_local\n",
    "    dev_local = qml.device(\"default.qubit\", wires=wires)\n",
    "    \n",
    "'''    \n",
    "    #Here dev_amazon_braket\n",
    "    my_bucket = f\"amazon-braket-Your-Bucket-Name\" # the name of the bucket\n",
    "    my_prefix = \"Your-Folder-Name\" # the name of the folder in the bucket\n",
    "    s3_folder = (my_bucket, my_prefix)\n",
    "\n",
    "    device_arn = \"arn:aws:braket:::device/quantum-simulator/amazon/sv1\"\n",
    "    \n",
    "    dev_amazon_braket = qml.device(\n",
    "      \"braket.aws.qubit\",\n",
    "    device_arn=device_arn,\n",
    "    wires=wires,\n",
    "    s3_destination_folder=s3_folder,\n",
    "    parallel=True,\n",
    ")\n",
    "    dev_amazon_braket = qml.device(\"braket.local.qubit\", wires=wires)\n",
    "'''\n",
    "    \n",
    "    @qml.qnode(dev_local, interface = \"tf\")\n",
    "    def circuit(phi, params):\n",
    "\n",
    "        # Encoding of 4 classical input values\n",
    "        for j in range(4):\n",
    "            qml.RY(np.pi * phi[j], wires=j)\n",
    "\n",
    "        for layer in range(params.shape[0]):\n",
    "            for i in range(params.shape[1]):\n",
    "                qml.Hadamard(wires=i)\n",
    "                qml.RY(np.pi * params[layer,i], wires=i)\n",
    "        qml.CNOT(wires = [0,1])\n",
    "        qml.CNOT(wires = [0,2])\n",
    "        qml.CNOT(wires = [1,3])\n",
    "            \n",
    "\n",
    "        # Measurement producing 4 classical output values\n",
    "        return qml.probs(wires = range(4))\n",
    "        \n",
    "\n",
    "    filters = 1\n",
    "    layers = 1\n",
    "    wires = 4\n",
    "    out_h1 = 64\n",
    "    out_h2 = 10\n",
    "    params = tf.Variable(tf.cast(tf.random.normal([filters,layers, wires]), dtype = tf.float64))\n",
    "    W1 = tf.Variable(tf.cast(tf.random.normal((14 * 14 * filters, out_h1)), dtype = tf.float64))\n",
    "    b1 = tf.Variable(tf.cast(tf.random.normal((out_h1,)), dtype = tf.float64))\n",
    "    W2 = tf.Variable(tf.cast(tf.random.normal((out_h1, out_h2)), dtype = tf.float64))\n",
    "    b2 = tf.Variable(tf.cast(tf.random.normal((out_h2,)), dtype = tf.float64))\n",
    "    \n",
    "    def x_hidden(x,W,b):\n",
    "        x = tf.cast(x, dtype = tf.float64)\n",
    "        return tf.nn.softmax(x @ W + b)\n",
    "    \n",
    "    def to_vector(n):\n",
    "        L = [0] * 10\n",
    "        L[n] = 1\n",
    "        return tf.cast(tf.convert_to_tensor(L), dtype = tf.float64)\n",
    "\n",
    "    losses = []\n",
    "    for i in range(n_epochs):\n",
    "        print(\"epoch\", i + 1)\n",
    "        epoch_loss = 0\n",
    "        for j in range(n_train):\n",
    "            with tf.GradientTape() as tape:\n",
    "                image = tf.reshape(quanv(train_images[j], params, filters),[1,-1])\n",
    "                o1 = x_hidden(image,W1,b1)\n",
    "                o2 = x_hidden(o1,W2,b2)\n",
    "                label = tf.reshape(to_vector(train_labels[j]) , o2.shape)\n",
    "                loss = sum((o2 - label)[0] ** 2)\n",
    "                # comprobar como esta definido el error, creo que algo falla\n",
    "                epoch_loss += loss\n",
    "                print(loss)\n",
    "        \n",
    "            gradients = tape.gradient(loss, [params,W1,b1, W2, b2])\n",
    "            \n",
    "            lr_c = 0.1\n",
    "            lr_q = 0.5\n",
    "            params = tf.Variable(params - lr_q * gradients[0])\n",
    "            W1 = tf.Variable(W1 - lr_c * gradients[1])\n",
    "            b1 = tf.Variable(b1 - lr_c * gradients[2])\n",
    "            W2 = tf.Variable(W2 - lr_c * gradients[3])\n",
    "            b2 = tf.Variable(b2 - lr_c * gradients[4])\n",
    "   \n",
    "\n",
    "        losses.append(epoch_loss)\n",
    "\n",
    "# at least it seems that it is training, we should put it in the network and change this error function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resource Estimate: \n",
    "Identify bottleneck in quantum classical hybrid models (number of learnt parameters in ansatz, gate overhead of encoding pixel values and size of dataset). Keep the classical layers not too deep to allow for efficient classical training. Explore the trade-off of number of run epochs and accuracy, the complexity/expressive power of the ansatz and the accuracy, number of quantum vs classical parameters and time complexity benchmark of the hybrid training loop time.\n",
    "\n",
    "<img src=\"AmazonLambda.jpeg\" width=50%, height=50% >\n",
    "\n",
    "To achieve our goal, we defined a scenario in which we implement a classic convolutional network with the Tensorflow framework. The idea is to use the 4000 $ credit to use an AWS Lambda function controller in Python [3] and to parallelize. And also, for computing gradients in parallel with the Pennylane-Braket plugin.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "1. Liu, Junhua, et al. \"Hybrid quantum-classical convolutional neural networks.\" arXiv preprint arXiv:1911.02998 (2019).\n",
    "\n",
    "2. Henderson, Maxwell, et al. \"Quanvolutional neural networks: powering image recognition with quantum circuits.\" Quantum Machine Intelligence 2.1 (2020): 1-9.\n",
    "\n",
    "   \n",
    "3. https://docs.aws.amazon.com/es_es/lambda/latest/dg/python-handler.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
